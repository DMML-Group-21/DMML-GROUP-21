{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ln8q979HhRrL"
   },
   "source": [
    "https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb\n",
    "https://colab.research.google.com/github/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb#scrollTo=E-hlmIU5tN3P\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Yp2x5NphRrR"
   },
   "source": [
    "# Tutorial 1 (housing) Data Exploration and Visualization (Getting to know your data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3G2agedJhRrS"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "UJMHBNTNhRrS"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "# Python ≥3.5 is required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rEM0Cu7xhRrU"
   },
   "outputs": [],
   "source": [
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "kBhrMzIvhRrV"
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "F0MqHkqGhRrW"
   },
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1PFyyJfhRrX"
   },
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVD91J2YhRrX"
   },
   "source": [
    "With this code, we download and store the tgz file and extract it on the same location of the notebook and sub folders \"datasets/housing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"US_Accidents_Dec21_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jx67hw8hRrd",
    "outputId": "b7367d26-67ea-430f-82de-02c2c75f76bc"
   },
   "outputs": [],
   "source": [
    "#This method prints information about a DataFrame including the dtype and columns, non-null values and memory usage.\n",
    "data.info() \n",
    "#Q2 Can you tell if there are any missing values? If yes, which attribuites contain missing values ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "co0dQ38ShRrf"
   },
   "source": [
    "All attributes are numerical, except the ocean_proximity field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "UCE1jukBhRrg",
    "outputId": "09d3e84c-557a-47ac-dbbc-8add01ed3c31"
   },
   "outputs": [],
   "source": [
    "#This method shows a statistical summary of the numerical attributes \n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTWv5nPvhRrh"
   },
   "source": [
    "The count, mean, min, and max rows are self-explanatory. Note that the null values are ignored (so, for example, the count of total_bedrooms is 20,433, not 20,640).\n",
    "\n",
    "The 25%, 50%, and 75% rows show the corresponding percentiles: a percentile indicates the value below which a given percentage of observations in a group of observations fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 838
    },
    "id": "zL4M1klihRri",
    "outputId": "daab2804-eae7-421b-c2f3-4cc1fb38c6d0"
   },
   "outputs": [],
   "source": [
    "#To plot a histogram for each numerical attribute\n",
    "data.hist(bins=50, figsize=(20,15))\n",
    "plt.show()\n",
    "# Q4 List down the main observations you noted from the statistical summary and the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = data.City.unique()\n",
    "len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfAccidentsPerCity = data.City.value_counts()\n",
    "numOfAccidentsPerCity.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weatherconditions = data.Weather_Condition.value_counts().reset_index()\n",
    "Weatherconditions.columns = ['Weather_Condition','Accidents']\n",
    "Weatherconditions['Percentage'] = round(Weatherconditions['Accidents'] * 100 /Weatherconditions['Accidents'].sum() , 2)\n",
    "Weatherconditions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Severitycounts = data.Severity.value_counts().reset_index()\n",
    "Severitycounts.columns = ['Severity','Accidents']\n",
    "Severitycounts['Percentage'] = round(Severitycounts['Accidents'] * 100 /Severitycounts['Accidents'].sum() , 2)\n",
    "Severitycounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGnSGS0whRrj"
   },
   "source": [
    "# Correlations and Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPFFmODqhRrm"
   },
   "outputs": [],
   "source": [
    "# Now we will look at the correlation of all the attributes with the expected class attribute (median-house-value)\n",
    "corr_matrix = data.corr() # computes the standard correlation coefficient (Pearson’s r) between every pair of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfAccidentsPerCity[:20].plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weathertypes[:20].plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HL9bYSdZhRrn",
    "outputId": "6983d728-179b-4c9e-91c0-8bf7f6b40839"
   },
   "outputs": [],
   "source": [
    "corr_matrix[\"Severity\"].sort_values(ascending=False)\n",
    "# Most correlated attributes to Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "pM2GqEYNhRrn",
    "outputId": "7e6339f4-456d-4854-909e-c2e9023f1501",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"Severity\"]\n",
    "scatter_matrix(data[attributes], figsize=(12, 8))\n",
    "# Another way to check for correlation between attributes is to use the pandas scatter_matrix() function above\n",
    "# Here we choose to plot 4 promising  numerical attributes against each other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(x=\"Severity\", y=\"Humidity(%)\", data=data)\n",
    "plt.ylabel('Humidity(%)', fontsize=12)\n",
    "plt.xlabel('Severity', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(x=\"Severity\", y=\"Temperature(F)\", data=data)\n",
    "plt.ylabel('Temperature(Farenheit)', fontsize=10)\n",
    "plt.xlabel('Severity', fontsize=10)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(x=\"Severity\", y=\"Wind_Chill(F)\", data=data)\n",
    "plt.ylabel('Wind_Chill(F)', fontsize=10)\n",
    "plt.xlabel('Severity', fontsize=10)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1FkaLeIhRrp"
   },
   "source": [
    "# Experimenting with Attribute Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DweFnW83hRrq"
   },
   "outputs": [],
   "source": [
    "# Here you will generate new features. This is what we call feature engineering\n",
    "# Q8 What are the new features that you are generating? Do they make sense ?\n",
    "\n",
    "data[\"latitude_diff\"] = data[\"End_Lat\"]-data[\"Start_Lat\"]\n",
    "\n",
    "#Calculate total time of accident\n",
    "data[\"Total_Time(hrs)\"] = pd.to_datetime(data['End_Time'])-pd.to_datetime(data['Start_Time'])\n",
    "data['Total_Time(hrs)'] = pd.to_timedelta(data['Total_Time(hrs)'])\n",
    "data['Total_Time(hrs)']=data['Total_Time(hrs)'].dt.total_seconds()/3600  \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-br1J7qlhRrv"
   },
   "outputs": [],
   "source": [
    "#Q10 Plot the scatter plot of the rooms_per_household against median_house_value\n",
    "#Q11 Now use the housing describe method to view the statistical summary of the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLo6wzD-hRrx"
   },
   "source": [
    "# Prepare the Data for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZZ9Tv3UhRr1"
   },
   "source": [
    "## Data Cleaning\n",
    "Dealing with missing features\n",
    "\n",
    "\n",
    "1. Get rid of the corresponding districts. `dropna()`\n",
    "2. Get rid of the whole attribute. `drop()` \n",
    "3. Set the values to some value (zero, the mean, the median, etc.)  `fillna()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "mBWtt3e1hRr1",
    "outputId": "b8688a51-77d7-4d7c-986b-89b5e8bb978e"
   },
   "outputs": [],
   "source": [
    "sample_incomplete_rows = data[data.isnull().any(axis=1)].head()\n",
    "sample_incomplete_rows   # display rows with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "yo7TMCgFhRr2",
    "outputId": "10f515f4-d6da-4e05-8887-a4081661daa8"
   },
   "outputs": [],
   "source": [
    "# option 1 Remove the records (i.e rows ) with missing values.\n",
    "sample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])  \n",
    "#Q12 What is displayed below? Note your observation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "My_obND_hRr3",
    "outputId": "477c1e85-2d5b-4c93-8713-f25e07ffdd56"
   },
   "outputs": [],
   "source": [
    "sample_incomplete_rows.drop(\"total_bedrooms\", axis=1)        # option 2 Remove the entire attribute with the missing value\n",
    "#Q13  What do you see now? How is this different from your observation in Q12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_D8hGfLGhRr4"
   },
   "outputs": [],
   "source": [
    "median = housing[\"total_bedrooms\"].median() # calculate the median of total_bedrooms\n",
    "sample_incomplete_rows[\"total_bedrooms\"].fillna(median, inplace=True) # option 3 Fill missing value with  median\n",
    "# Q14 Note your observation in the displayed rows below. How is it different from Q12 and Q13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "2t11ShG6hRr4",
    "outputId": "4c08be5f-a80d-4957-941e-ed524f7f162a"
   },
   "outputs": [],
   "source": [
    "sample_incomplete_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnX7vYm2hRr5"
   },
   "source": [
    "## Scikit-Learn solution (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyOLU4ClhRr6"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer      # Look up SimpleImputer Class in Sklearn Documenation\n",
    "imputer = SimpleImputer(strategy=\"median\")    # Replace each missing attribute with median of that attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFC2uLDmhRr7"
   },
   "outputs": [],
   "source": [
    "#We cant compute the median of a categorical data, therefore we are creating a copy of the data without ocean_prox\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2o5sV5I4hRr8",
    "outputId": "c6fa4095-ba17-41ed-b8b6-c89a5dc05d09"
   },
   "outputs": [],
   "source": [
    "imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjn5yCXnhRr8"
   },
   "source": [
    "The imputer has simply computed the median of each attribute and stored the result in its `statistics_` instance variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zg6TgmeGhRr8",
    "outputId": "33945d78-4218-4081-b5e8-3e4a24e7452f"
   },
   "outputs": [],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJhzkVCnhRr8",
    "outputId": "7a5d346f-fa6c-4520-fe06-6db584a27c15"
   },
   "outputs": [],
   "source": [
    "housing_num.median().values #Check that this is the same as manually computing the median of each attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8x0W2Z-0hRr9"
   },
   "outputs": [],
   "source": [
    "X = imputer.transform(housing_num) # transform the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJbltHl7hRr-"
   },
   "outputs": [],
   "source": [
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
    "                          index=housing_num.index) # load the new tranformed data set into the pandas frame housing_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "MEBesDPHhRr-",
    "outputId": "458bba23-4d7c-42de-89a7-bc0b63c9fd2f"
   },
   "outputs": [],
   "source": [
    "housing_tr.loc[sample_incomplete_rows.index.values] # show the rows with previously missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6xyVgYlhRr_"
   },
   "source": [
    "### Handling Text and Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "b1F5WdRThRsA",
    "outputId": "c944f9a3-d6ca-47ba-b972-362ae02f7e12"
   },
   "outputs": [],
   "source": [
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "housing_cat.head(10)  # look at the value of  'ocean_proximity' for the first 10 instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "EECQACwDhRsA",
    "outputId": "f47dda29-6672-4a85-fc3d-beca71b9d0d8"
   },
   "outputs": [],
   "source": [
    "housing_cat.tail(10)\n",
    "# look at the value of  'ocean_proximity' for the last 10 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3HrUaaNhRsB",
    "outputId": "6fb20fa6-4f4a-4710-90d1-f199dde5838a"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# sklearn OrdinalEncoder class is used to convert categorical values to numbers\n",
    "ordinal_encoder = OrdinalEncoder() \n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded[:10] # Lists the numerical values that correspond to the categorical attribute\n",
    "# Q15 Why can representing a catogorical variable with numbers be a problem in ML?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xtawqcnxhRsB",
    "outputId": "3fe6f28c-2c36-4e12-fcd2-021183bb5386"
   },
   "outputs": [],
   "source": [
    "# 1 D array of categories for the attribute 'ocean-proximity'\n",
    "ordinal_encoder.categories_ # prints the categories for all categorical attributes , here we only have one categorical attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4wnlCPPhRsB",
    "outputId": "b217a828-8154-444e-f88e-8887053f9cf1"
   },
   "outputs": [],
   "source": [
    "# An alternative way to represent a categorical attribuite is to use 'one-hot-encoding'\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder  \n",
    "# OneHotEncoder class converts categorical values into one-hot vectors , this assumes no order so better for categorical variables\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vb4HvpfwhRsC",
    "outputId": "8c8fda04-2019-4345-ba2b-e6d74a360395"
   },
   "outputs": [],
   "source": [
    "type(housing_cat_1hot) # This is a SciPy sparce matrix ( not a NumPy array)\n",
    "# a sparse matrix only stores the location of the non‐zero enties , therefore saves memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pTa74wdVhRsC",
    "outputId": "823cd462-6e8b-48d6-fcb5-bb5dd7f4aebf"
   },
   "outputs": [],
   "source": [
    "housing_cat_1hot.toarray() # To convert it to a (dense) NumPy array, call toarrray() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pohHpDVYhRsD",
    "outputId": "d65049f2-9516-4030-e307-55c280237f66"
   },
   "outputs": [],
   "source": [
    "cat_encoder = OneHotEncoder(sparse=False) # Alternatively, you can set sparse=False when creating the OneHotEncoder\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alCjsVt0hRsD",
    "outputId": "6764030b-e81d-43dd-de80-3eae1966d7dc"
   },
   "outputs": [],
   "source": [
    "cat_encoder.categories_         # Get a list of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kpf91WUuPUK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABf7NG4xtEKS"
   },
   "source": [
    "### Feature Scaling (optional)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQwkH7i_ts13"
   },
   "source": [
    "In week 2 lectures you have learned about two common ways to get all attributes to have the same scale: min-max scaling and standardization (Zscore).\n",
    "\n",
    "Sklearn provides two transformer functions for this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVur3HpBuRje"
   },
   "outputs": [],
   "source": [
    "#Q16 Research sklearn documentation for the functions MinMaxScaler() and StandardScaler() and try to experiment with it on the housing data set"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tutorial 1  Data Exploration and Visualization (Getting to know your data).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "efb9f42aedd77c290c9ac444bca03d1d08f2eedfa00a5af02c90bac9443c2ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
